{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "import gym\n",
    "\n",
    "ENV_NAME = 'CarRacing-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Box(0, 255, (96, 96, 3), uint8) (96, 96, 3)\nBox(-1.0, 1.0, (3,), float32) (3,)\n"
     ]
    }
   ],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.shape[0]\n",
    "print(env.observation_space, env.observation_space.shape)\n",
    "print(env.action_space, env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 27648)             0         \n_________________________________________________________________\ndense (Dense)                (None, 16)                442384    \n_________________________________________________________________\nactivation (Activation)      (None, 16)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                272       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 16)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                272       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 16)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 51        \n_________________________________________________________________\nactivation_3 (Activation)    (None, 3)                 0         \n=================================================================\nTotal params: 442,979\nTrainable params: 442,979\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(8192))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(4096))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(1024))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('linear'))\n",
    "actor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nobservation_input (InputLayer)  [(None, 1, 96, 96, 3 0                                            \n__________________________________________________________________________________________________\naction_input (InputLayer)       [(None, 3)]          0                                            \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 27648)        0           observation_input[0][0]          \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 27651)        0           action_input[0][0]               \n                                                                 flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 32)           884864      concatenate[0][0]                \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 32)           0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 32)           1056        activation_4[0][0]               \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 32)           0           dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 32)           1056        activation_5[0][0]               \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32)           0           dense_6[0][0]                    \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 1)            33          activation_6[0][0]               \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 1)            0           dense_7[0][0]                    \n==================================================================================================\nTotal params: 887,009\nTrainable params: 887,009\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(8192)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(4096)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1024)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "source": [
    "# Finally, we configure and compile our agent. You can use every built-in tensorflow.keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.99, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training for 50000 steps ...\n",
      "Track generation: 1234..1551 -> 317-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1225..1535 -> 310-tiles track\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "  199/10000 [..............................] - ETA: 3:29 - reward: -0.0349Track generation: 1172..1469 -> 297-tiles track\n",
      "  399/10000 [>.............................] - ETA: 4:08 - reward: -0.0252Track generation: 1063..1336 -> 273-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "  599/10000 [>.............................] - ETA: 4:16 - reward: -0.0215Track generation: 1365..1709 -> 344-tiles track\n",
      "  800/10000 [=>............................] - ETA: 4:18 - reward: -0.0339Track generation: 1177..1485 -> 308-tiles track\n",
      "  999/10000 [=>............................] - ETA: 4:15 - reward: -0.0406Track generation: 1318..1652 -> 334-tiles track\n",
      " 1199/10000 [==>...........................] - ETA: 4:12 - reward: -0.0455Track generation: 1031..1293 -> 262-tiles track\n",
      " 1400/10000 [===>..........................] - ETA: 4:09 - reward: -0.0478Track generation: 1196..1508 -> 312-tiles track\n",
      " 1599/10000 [===>..........................] - ETA: 4:03 - reward: -0.0503Track generation: 1349..1690 -> 341-tiles track\n",
      " 1800/10000 [====>.........................] - ETA: 3:58 - reward: -0.0526Track generation: 1126..1411 -> 285-tiles track\n",
      " 1999/10000 [====>.........................] - ETA: 3:53 - reward: -0.0538Track generation: 1244..1559 -> 315-tiles track\n",
      " 2200/10000 [=====>........................] - ETA: 3:47 - reward: -0.0493Track generation: 1187..1488 -> 301-tiles track\n",
      " 2399/10000 [======>.......................] - ETA: 3:42 - reward: -0.0507Track generation: 1143..1433 -> 290-tiles track\n",
      " 2599/10000 [======>.......................] - ETA: 3:37 - reward: -0.0465Track generation: 1159..1454 -> 295-tiles track\n",
      " 2800/10000 [=======>......................] - ETA: 3:32 - reward: -0.0467Track generation: 1109..1390 -> 281-tiles track\n",
      " 2999/10000 [=======>......................] - ETA: 3:26 - reward: -0.0455Track generation: 1067..1338 -> 271-tiles track\n",
      " 3199/10000 [========>.....................] - ETA: 3:21 - reward: -0.0466Track generation: 1215..1523 -> 308-tiles track\n",
      " 3399/10000 [=========>....................] - ETA: 3:15 - reward: -0.0478Track generation: 1140..1429 -> 289-tiles track\n",
      " 3599/10000 [=========>....................] - ETA: 3:09 - reward: -0.0440Track generation: 1077..1350 -> 273-tiles track\n",
      " 3799/10000 [==========>...................] - ETA: 3:04 - reward: -0.0421Track generation: 1089..1370 -> 281-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      " 3999/10000 [==========>...................] - ETA: 2:58 - reward: -0.0403Track generation: 1223..1533 -> 310-tiles track\n",
      " 4200/10000 [===========>..................] - ETA: 2:52 - reward: -0.0393Track generation: 1064..1334 -> 270-tiles track\n",
      " 4399/10000 [============>.................] - ETA: 2:46 - reward: -0.0386Track generation: 1220..1529 -> 309-tiles track\n",
      " 4600/10000 [============>.................] - ETA: 2:40 - reward: -0.0392Track generation: 1099..1381 -> 282-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1205..1510 -> 305-tiles track\n",
      " 4799/10000 [=============>................] - ETA: 2:35 - reward: -0.0390Track generation: 1276..1599 -> 323-tiles track\n",
      " 5000/10000 [==============>...............] - ETA: 2:29 - reward: -0.0383Track generation: 1105..1385 -> 280-tiles track\n",
      " 5199/10000 [==============>...............] - ETA: 2:23 - reward: -0.0359Track generation: 1007..1263 -> 256-tiles track\n",
      " 5399/10000 [===============>..............] - ETA: 2:17 - reward: -0.0339Track generation: 1129..1415 -> 286-tiles track\n",
      " 5599/10000 [===============>..............] - ETA: 2:12 - reward: -0.0319Track generation: 1311..1643 -> 332-tiles track\n",
      " 5799/10000 [================>.............] - ETA: 2:06 - reward: -0.0316Track generation: 997..1252 -> 255-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1143..1440 -> 297-tiles track\n",
      " 5999/10000 [================>.............] - ETA: 2:00 - reward: -0.0328Track generation: 1152..1444 -> 292-tiles track\n",
      " 6199/10000 [=================>............] - ETA: 1:54 - reward: -0.0338Track generation: 1177..1476 -> 299-tiles track\n",
      " 6400/10000 [==================>...........] - ETA: 1:48 - reward: -0.0296Track generation: 1155..1419 -> 264-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1071..1343 -> 272-tiles track\n",
      " 6600/10000 [==================>...........] - ETA: 1:42 - reward: -0.0289Track generation: 1130..1417 -> 287-tiles track\n",
      " 6800/10000 [===================>..........] - ETA: 1:36 - reward: -0.0290Track generation: 1126..1411 -> 285-tiles track\n",
      " 6999/10000 [===================>..........] - ETA: 1:30 - reward: -0.0280Track generation: 1039..1304 -> 265-tiles track\n",
      " 7200/10000 [====================>.........] - ETA: 1:24 - reward: -0.0258Track generation: 1195..1498 -> 303-tiles track\n",
      " 7400/10000 [=====================>........] - ETA: 1:18 - reward: -0.0255Track generation: 1086..1368 -> 282-tiles track\n",
      " 7599/10000 [=====================>........] - ETA: 1:12 - reward: -0.0266Track generation: 1076..1349 -> 273-tiles track\n",
      " 7799/10000 [======================>.......] - ETA: 1:06 - reward: -0.0256Track generation: 1068..1347 -> 279-tiles track\n",
      " 8000/10000 [=======================>......] - ETA: 1:00 - reward: -0.0248Track generation: 1260..1579 -> 319-tiles track\n",
      " 8199/10000 [=======================>......] - ETA: 54s - reward: -0.0251Track generation: 1088..1364 -> 276-tiles track\n",
      " 8399/10000 [========================>.....] - ETA: 48s - reward: -0.0247Track generation: 1175..1473 -> 298-tiles track\n",
      " 8599/10000 [========================>.....] - ETA: 42s - reward: -0.0245Track generation: 1103..1383 -> 280-tiles track\n",
      " 8799/10000 [=========================>....] - ETA: 36s - reward: -0.0250Track generation: 1186..1488 -> 302-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1079..1353 -> 274-tiles track\n",
      " 8999/10000 [=========================>....] - ETA: 30s - reward: -0.0250Track generation: 1251..1567 -> 316-tiles track\n",
      " 9199/10000 [==========================>...] - ETA: 24s - reward: -0.0249Track generation: 1256..1574 -> 318-tiles track\n",
      " 9399/10000 [===========================>..] - ETA: 18s - reward: -0.0248Track generation: 1182..1480 -> 298-tiles track\n",
      " 9599/10000 [===========================>..] - ETA: 12s - reward: -0.0247Track generation: 1043..1316 -> 273-tiles track\n",
      " 9799/10000 [============================>.] - ETA: 6s - reward: -0.0247Track generation: 1116..1399 -> 283-tiles track\n",
      "10000/10000 [==============================] - 303s 30ms/step - reward: -0.0244\n",
      "Track generation: 1343..1683 -> 340-tiles track\n",
      "50 episodes - episode_reward: -4.887 [-14.169, 20.268] - loss: 9535.767 - mae: 74.851 - mean_q: -1096.711\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "  199/10000 [..............................] - ETA: 5:02 - reward: -0.0259Track generation: 1016..1274 -> 258-tiles track\n",
      "  400/10000 [>.............................] - ETA: 4:58 - reward: -0.0145Track generation: 1381..1730 -> 349-tiles track\n",
      "  599/10000 [>.............................] - ETA: 4:53 - reward: -0.0189Track generation: 1375..1723 -> 348-tiles track\n",
      "  799/10000 [=>............................] - ETA: 4:45 - reward: -0.0212Track generation: 1017..1275 -> 258-tiles track\n",
      "  999/10000 [=>............................] - ETA: 4:59 - reward: -0.0175Track generation: 1200..1511 -> 311-tiles track\n",
      " 1200/10000 [==>...........................] - ETA: 4:49 - reward: -0.0179Track generation: 1161..1455 -> 294-tiles track\n",
      " 1399/10000 [===>..........................] - ETA: 4:41 - reward: -0.0173Track generation: 1209..1515 -> 306-tiles track\n",
      " 1600/10000 [===>..........................] - ETA: 4:33 - reward: -0.0175Track generation: 1019..1284 -> 265-tiles track\n",
      " 1799/10000 [====>.........................] - ETA: 4:26 - reward: -0.0161Track generation: 1099..1378 -> 279-tiles track\n",
      " 1999/10000 [====>.........................] - ETA: 4:19 - reward: -0.0155Track generation: 1008..1269 -> 261-tiles track\n",
      " 2199/10000 [=====>........................] - ETA: 4:11 - reward: -0.0162Track generation: 1145..1437 -> 292-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1200..1504 -> 304-tiles track\n",
      " 2399/10000 [======>.......................] - ETA: 4:04 - reward: -0.0163Track generation: 1176..1474 -> 298-tiles track\n",
      " 2599/10000 [======>.......................] - ETA: 3:58 - reward: -0.0162Track generation: 1100..1379 -> 279-tiles track\n",
      " 2799/10000 [=======>......................] - ETA: 3:51 - reward: -0.0158Track generation: 1184..1484 -> 300-tiles track\n",
      " 2999/10000 [=======>......................] - ETA: 3:44 - reward: -0.0158Track generation: 1199..1503 -> 304-tiles track\n",
      " 3200/10000 [========>.....................] - ETA: 3:38 - reward: -0.0160Track generation: 1114..1399 -> 285-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1045..1316 -> 271-tiles track\n",
      " 3399/10000 [=========>....................] - ETA: 3:31 - reward: -0.0165Track generation: 1075..1348 -> 273-tiles track\n",
      " 3599/10000 [=========>....................] - ETA: 3:25 - reward: -0.0120Track generation: 1219..1528 -> 309-tiles track\n",
      " 3799/10000 [==========>...................] - ETA: 3:18 - reward: -0.0123Track generation: 1108..1389 -> 281-tiles track\n",
      " 3999/10000 [==========>...................] - ETA: 3:12 - reward: -0.0123Track generation: 1163..1458 -> 295-tiles track\n",
      " 4199/10000 [===========>..................] - ETA: 3:05 - reward: -0.0124Track generation: 1122..1407 -> 285-tiles track\n",
      " 4399/10000 [============>.................] - ETA: 2:59 - reward: -0.0124Track generation: 1312..1644 -> 332-tiles track\n",
      " 4599/10000 [============>.................] - ETA: 2:52 - reward: -0.0129Track generation: 1220..1538 -> 318-tiles track\n",
      " 4800/10000 [=============>................] - ETA: 2:46 - reward: -0.0139Track generation: 1032..1301 -> 269-tiles track\n",
      " 5000/10000 [==============>...............] - ETA: 2:39 - reward: -0.0144Track generation: 1320..1654 -> 334-tiles track\n",
      " 5200/10000 [==============>...............] - ETA: 2:33 - reward: -0.0148Track generation: 1188..1489 -> 301-tiles track\n",
      " 5399/10000 [===============>..............] - ETA: 2:27 - reward: -0.0148Track generation: 1047..1313 -> 266-tiles track\n",
      " 5600/10000 [===============>..............] - ETA: 2:20 - reward: -0.0145Track generation: 1299..1636 -> 337-tiles track\n",
      " 5800/10000 [================>.............] - ETA: 2:14 - reward: -0.0139Track generation: 1194..1496 -> 302-tiles track\n",
      " 6000/10000 [=================>............] - ETA: 2:07 - reward: -0.0134Track generation: 1119..1413 -> 294-tiles track\n",
      " 6199/10000 [=================>............] - ETA: 2:01 - reward: -0.0129Track generation: 1148..1439 -> 291-tiles track\n",
      " 6400/10000 [==================>...........] - ETA: 1:55 - reward: -0.0113Track generation: 1032..1301 -> 269-tiles track\n",
      " 6600/10000 [==================>...........] - ETA: 1:48 - reward: -0.0129Track generation: 1127..1413 -> 286-tiles track\n",
      " 6799/10000 [===================>..........] - ETA: 1:42 - reward: -0.0144Track generation: 1413..1769 -> 356-tiles track\n",
      " 6999/10000 [===================>..........] - ETA: 1:35 - reward: -0.0160Track generation: 1188..1497 -> 309-tiles track\n",
      " 7199/10000 [====================>.........] - ETA: 1:29 - reward: -0.0175Track generation: 1045..1313 -> 268-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1077..1350 -> 273-tiles track\n",
      " 7400/10000 [=====================>........] - ETA: 1:23 - reward: -0.0187Track generation: 1268..1596 -> 328-tiles track\n",
      " 7599/10000 [=====================>........] - ETA: 1:16 - reward: -0.0192Track generation: 1107..1397 -> 290-tiles track\n",
      " 7799/10000 [======================>.......] - ETA: 1:10 - reward: -0.0204Track generation: 1274..1601 -> 327-tiles track\n",
      " 7999/10000 [======================>.......] - ETA: 1:04 - reward: -0.0216Track generation: 1163..1458 -> 295-tiles track\n",
      " 8199/10000 [=======================>......] - ETA: 57s - reward: -0.0227Track generation: 1206..1513 -> 307-tiles track\n",
      " 8400/10000 [========================>.....] - ETA: 51s - reward: -0.0238Track generation: 1135..1428 -> 293-tiles track\n",
      " 8599/10000 [========================>.....] - ETA: 44s - reward: -0.0248Track generation: 1175..1473 -> 298-tiles track\n",
      " 8799/10000 [=========================>....] - ETA: 38s - reward: -0.0257Track generation: 1030..1297 -> 267-tiles track\n",
      " 9000/10000 [==========================>...] - ETA: 32s - reward: -0.0265Track generation: 1067..1338 -> 271-tiles track\n",
      " 9199/10000 [==========================>...] - ETA: 25s - reward: -0.0273Track generation: 1059..1328 -> 269-tiles track\n",
      " 9399/10000 [===========================>..] - ETA: 19s - reward: -0.0281Track generation: 1127..1413 -> 286-tiles track\n",
      " 9599/10000 [===========================>..] - ETA: 12s - reward: -0.0288Track generation: 1133..1421 -> 288-tiles track\n",
      " 9800/10000 [============================>.] - ETA: 6s - reward: -0.0296Track generation: 998..1256 -> 258-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1134..1421 -> 287-tiles track\n",
      "10000/10000 [==============================] - 322s 32ms/step - reward: -0.0303\n",
      "Track generation: 1189..1490 -> 301-tiles track\n",
      "50 episodes - episode_reward: -6.059 [-14.366, 13.088] - loss: 25476.543 - mae: 95.852 - mean_q: -2918.346\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:23 - reward: -0.0667Track generation: 1157..1450 -> 293-tiles track\n",
      "  400/10000 [>.............................] - ETA: 4:59 - reward: -0.0662Track generation: 1088..1367 -> 279-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1137..1425 -> 288-tiles track\n",
      "  599/10000 [>.............................] - ETA: 4:46 - reward: -0.0658Track generation: 1260..1579 -> 319-tiles track\n",
      "  799/10000 [=>............................] - ETA: 4:39 - reward: -0.0665Track generation: 1231..1543 -> 312-tiles track\n",
      "  999/10000 [=>............................] - ETA: 4:31 - reward: -0.0668Track generation: 1048..1321 -> 273-tiles track\n",
      " 1200/10000 [==>...........................] - ETA: 4:24 - reward: -0.0662Track generation: 1144..1434 -> 290-tiles track\n",
      " 1399/10000 [===>..........................] - ETA: 4:18 - reward: -0.0661Track generation: 1335..1673 -> 338-tiles track\n",
      " 1599/10000 [===>..........................] - ETA: 4:11 - reward: -0.0666Track generation: 1250..1567 -> 317-tiles track\n",
      " 1800/10000 [====>.........................] - ETA: 4:05 - reward: -0.0668Track generation: 1119..1403 -> 284-tiles track\n",
      " 1999/10000 [====>.........................] - ETA: 10:22 - reward: -0.0666Track generation: 1303..1633 -> 330-tiles track\n",
      " 2200/10000 [=====>........................] - ETA: 10:05 - reward: -0.0669Track generation: 1135..1423 -> 288-tiles track\n",
      " 2400/10000 [======>.......................] - ETA: 9:45 - reward: -0.0580Track generation: 1130..1427 -> 297-tiles track\n",
      " 2600/10000 [======>.......................] - ETA: 9:52 - reward: -0.0547Track generation: 1108..1389 -> 281-tiles track\n",
      " 2799/10000 [=======>......................] - ETA: 9:41 - reward: -0.0516Track generation: 1396..1749 -> 353-tiles track\n",
      " 2999/10000 [=======>......................] - ETA: 9:41 - reward: -0.0501Track generation: 1187..1488 -> 301-tiles track\n",
      " 3200/10000 [========>.....................] - ETA: 10:07 - reward: -0.0480Track generation: 1131..1418 -> 287-tiles track\n",
      " 3400/10000 [=========>....................] - ETA: 9:48 - reward: -0.0428Track generation: 1097..1383 -> 286-tiles track\n",
      " 3600/10000 [=========>....................] - ETA: 9:27 - reward: -0.0421Track generation: 1186..1486 -> 300-tiles track\n",
      " 3799/10000 [==========>...................] - ETA: 9:04 - reward: -0.0407Track generation: 1318..1659 -> 341-tiles track\n",
      " 4000/10000 [===========>..................] - ETA: 8:43 - reward: -0.0408Track generation: 1280..1604 -> 324-tiles track\n",
      " 4200/10000 [===========>..................] - ETA: 8:22 - reward: -0.0399Track generation: 1087..1369 -> 282-tiles track\n",
      " 4400/10000 [============>.................] - ETA: 8:01 - reward: -0.0394Track generation: 1251..1568 -> 317-tiles track\n",
      " 4600/10000 [============>.................] - ETA: 7:44 - reward: -0.0386Track generation: 1176..1474 -> 298-tiles track\n",
      " 4800/10000 [=============>................] - ETA: 7:26 - reward: -0.0377Track generation: 1128..1414 -> 286-tiles track\n",
      " 5000/10000 [==============>...............] - ETA: 7:08 - reward: -0.0366Track generation: 1102..1382 -> 280-tiles track\n",
      " 5200/10000 [==============>...............] - ETA: 6:55 - reward: -0.0356Track generation: 1183..1493 -> 310-tiles track\n",
      " 5400/10000 [===============>..............] - ETA: 6:41 - reward: -0.0356Track generation: 974..1224 -> 250-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1064..1340 -> 276-tiles track\n",
      " 5599/10000 [===============>..............] - ETA: 6:38 - reward: -0.0353Track generation: 1139..1428 -> 289-tiles track\n",
      " 5800/10000 [================>.............] - ETA: 6:31 - reward: -0.0364Track generation: 1154..1452 -> 298-tiles track\n",
      " 6000/10000 [=================>............] - ETA: 6:37 - reward: -0.0374Track generation: 952..1200 -> 248-tiles track\n",
      " 6198/10000 [=================>............] - ETA: 6:56 - reward: -0.0380"
     ]
    }
   ],
   "source": [
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -122.348, steps: 200\n",
      "Episode 2: reward: -357.962, steps: 200\n",
      "Episode 3: reward: -120.219, steps: 200\n",
      "Episode 4: reward: -116.302, steps: 200\n",
      "Episode 5: reward: -127.116, steps: 200\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec504a7580>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}